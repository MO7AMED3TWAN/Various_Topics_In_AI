{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4295a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTING LIBRARIES ####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1cf28c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high_GPA    0\n",
       "math_SAT    0\n",
       "verb_SAT    0\n",
       "comp_GPA    0\n",
       "univ_GPA    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### READ DATA ####\n",
    "path = r\"test2.csv \"\n",
    "data = pd.read_csv(path)\n",
    "data.isnull().sum() ## Get Nulls in My Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c9b2b1",
   "metadata": {},
   "source": [
    "# DEFINE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d3ce8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### define features and target and Theta ####\n",
    "\n",
    "X=data.iloc[:,:-1]\n",
    "y=data.iloc[:,-1]\n",
    "    \n",
    "# data.columns=['','','','','',...]#تعريف اسماء الاعمدة \n",
    "\n",
    "#### SPLITTING DATA ####\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245a4468",
   "metadata": {},
   "source": [
    "# SHOWING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa5f88a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105 entries, 0 to 104\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   high_GPA  105 non-null    float64\n",
      " 1   math_SAT  105 non-null    int64  \n",
      " 2   verb_SAT  105 non-null    int64  \n",
      " 3   comp_GPA  105 non-null    float64\n",
      " 4   univ_GPA  105 non-null    float64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 4.2 KB\n",
      "That's Information About My Data \n",
      "None\n",
      "\n",
      "\n",
      "That's My First 5 Rows IN My Data \n",
      "   high_GPA  math_SAT  verb_SAT  comp_GPA  univ_GPA\n",
      "0      3.45       643       589      3.76      3.52\n",
      "1      2.78       558       512      2.87      2.91\n",
      "2      2.52       583       503      2.54      2.40\n",
      "3      3.67       685       602      3.83      3.47\n",
      "4      3.24       592       538      3.29      3.47\n",
      "\n",
      "\n",
      "That's The Describtion Of My Data \n",
      "         high_GPA    math_SAT    verb_SAT    comp_GPA    univ_GPA\n",
      "count  105.000000  105.000000  105.000000  105.000000  105.000000\n",
      "mean     3.076381  623.076190  598.600000    3.128000    3.172857\n",
      "std      0.516598   53.760454   62.963604    0.509046    0.447194\n",
      "min      2.030000  516.000000  480.000000    2.030000    2.080000\n",
      "25%      2.670000  573.000000  548.000000    2.870000    3.010000\n",
      "50%      3.170000  612.000000  591.000000    3.210000    3.290000\n",
      "75%      3.480000  675.000000  645.000000    3.490000    3.470000\n",
      "max      4.000000  718.000000  732.000000    4.000000    3.810000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"That's Information About My Data \\n{data.info()}\\n\\n\")\n",
    "\n",
    "print(f\"That's My First 5 Rows IN My Data \\n{data.head()}\\n\\n\")\n",
    "\n",
    "print(f\"That's The Describtion Of My Data \\n{data.describe()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51762e9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), slice(1, 2, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:158\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), slice(1, 2, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      3\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 4\u001b[0m X_norm1 \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      5\u001b[0m X_norm2 \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X[:,\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      6\u001b[0m X_norm3 \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X[:,\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m4\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5974\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5970\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5971\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5972\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5973\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5974\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), slice(1, 2, None))"
     ]
    }
   ],
   "source": [
    "### Scale/normalize the training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_norm1 = scaler.fit_transform(X[:,1:2])\n",
    "X_norm2 = scaler.fit_transform(X[:,2:3])\n",
    "X_norm3 = scaler.fit_transform(X[:,3:4])\n",
    "X_norm4 = scaler.fit_transform(X[:,4:5])\n",
    "\n",
    "\n",
    "###Convert data to new data after scalling\n",
    "X[:,1:2]=X_norm1\n",
    "X[:,2:3]=X_norm2\n",
    "X[:,3:4]=X_norm3\n",
    "X[:,4:]=X_norm4\n",
    "\n",
    "print(f\"Peak to Peak range by column in Normalized X:{np.ptp(X_norm1,axis=0)}\")\n",
    "print(f\"Peak to Peak range by column in Normalized X:{np.ptp(X_norm2,axis=0)}\")\n",
    "print(f\"Peak to Peak range by column in Normalized X:{np.ptp(X_norm3,axis=0)}\")\n",
    "print(f\"Peak to Peak range by column in Normalized X:{np.ptp(X_norm4,axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe12b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### DATA SHOW After Normalization ####\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1, 4, figsize=(12, 3), sharey=True)\n",
    "ax[0].scatter(X_norm1,data.Y)\n",
    "ax[1].scatter(X_norm2,data.Y)\n",
    "ax[2].scatter(X_norm3,data.Y)\n",
    "ax[3].scatter(X_norm4,data.Y)\n",
    "\n",
    "ax[0].set_xlabel(\"X1\")\n",
    "ax[1].set_xlabel(\"X2\")\n",
    "ax[2].set_xlabel(\"X3\")\n",
    "ax[3].set_xlabel(\"X4\")\n",
    "\n",
    "ax[0].set_ylabel(\"TARGET\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f0890b-5528-43fd-96be-f0ad8876e749",
   "metadata": {},
   "source": [
    "# CREATE A MODEL OF PREDECTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fddbcb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "### MAKING MODEL ###\n",
    "L_G_MODEL=LinearRegression()\n",
    "\n",
    "### TRAINING MODEL ###\n",
    "L_G_MODEL.fit(X_train,y_train)\n",
    "\n",
    "### PREDECT BY MODEL ###\n",
    "Predect_Values=L_G_MODEL.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638b41b5-bc3f-498c-8a66-5e68ddd54cc2",
   "metadata": {},
   "source": [
    "## The Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d88c69-b490-4318-8d41-8c1cd6a4bd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 7.59019135e-02 -6.71421581e-04  5.63705071e-04  7.71085415e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: \\n\", L_G_MODEL.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b6066-fc19-4fd3-ba65-95da474b44a6",
   "metadata": {},
   "source": [
    "## SCORE OF ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bce692c-f855-4d45-866a-0246b912d319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.metrics import r2_score\n",
    "#----------------------------------------------------\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test,Predect_Values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e541b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error Value is :  0.1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "## \n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Absolute Error\n",
    "MAEValue = mean_absolute_error(y_test, Predect_Values) # it can be raw_values\n",
    "print('Mean Absolute Error Value is : ',round(MAEValue,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69de4649",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Value is :  0.0281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.metrics import mean_squared_error \n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Squared Error\n",
    "MSEValue = mean_squared_error(y_test, Predect_Values) # it can be raw_values\n",
    "print('Mean Squared Error Value is : ',round(MSEValue,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07427e90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Squared Error Value is :  0.0989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\MoHaMeD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.metrics import median_absolute_error\n",
    "#----------------------------------------------------\n",
    "#Calculating Median Squared Error\n",
    "MdSEValue = median_absolute_error(y_test, Predect_Values)\n",
    "print('Median Squared Error Value is : ',round(MdSEValue,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb5bc3",
   "metadata": {},
   "source": [
    "# THE END\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
